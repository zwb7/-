# Backgroun

Motivation：现有对shallow domain adaption已经有全面的调查，但很少回顾新兴的基于深度学习的方法。

Contribution：

•根据数据的属性给出了不同Deep DA场景的分类，这些数据定义来了两个域是如何发散的。

•扩展他人的工作，将基于train loss的方法归纳分类。

•考虑s和t的distance，研究multi-step，并将其分类。

•综述了CV方面的应用，突出了当前方法的不足和未来方向。

为什么要将DNN和DA相结合？

DNN可以学习到更多的可迁移的表示，但是domain shift仍会影响性能，迁移性在高层急剧降低。DNN在shallow layer的迁移性好，但是在更深层的迁移性迅速变差。

# One-step and multi-step

基于不同的domain divergences将DA分为homogeneous和heterogeneous DA。

homogeneous DA的source和target的特征空间和数据维度是相同的，但数据分布是不同的。比如都是图片，一个是淘宝上下载的，一个是现实中拍摄的。

heterogeneous DA的source和target的特征空间是不同的，维度也可能一般不同。比如源域现实中的图片，目标域是卡通图片，甚至源域是图片，目标域是文本。

homogeneous和heterogeneous都分为无监督，半监督，有监督。

One-step DA假设source与target直接相关，知识迁移可以一步完成。

Multi-step DA通过一些中间域连接两个域比如人脸图像和车辆图像差异大，通过引入头盔图像实现平滑的知识迁移。

# Homogeneous

GAN网络以mini-max不等式的方式对label prediction loss进行训练（同时优化generator以最小化损失，同时训练discriminator最大化分配正确label的概率）。在DA中这一原则确保网络无法区分source和target。ADDA框架根据是否使用生generator，使用哪种loss或是否跨域共享权重对现有方法进行总结。

# Generative models

CoGAN是一种学习source和target数据联合分布的nn，其由两个GAN网络组成。通过强制性的给两个网络加上共享参数的约束，限制了网络的能力，从而两个网络从噪声生成的数据是差不多的。文章认为generator的前几层是解码的高阶语义，所以通过共享权重对齐。discriminator后几层是解码的高阶语义，所以也共享权重对齐。这种权重的约束可以让网络在无监督的情况下，学习source和target图片的联合概率。所以该网络能用来生成成对的共享高阶语义，而低阶语义不同的图片，例如相同的前景，背景不同的图片。

Unsupervised pixel-level domain adaptation with generative adversarial networks

这篇文章和Pixel-level domain transfer方法很相似，通过一个generator，将source数据 Xs变成target的数据 Xf ，用一个discriminator来判别真假，当discriminator无法判别时，我们认为生成的数据Xf 就和真实目标域 Xt 差不多了。由于generator并不会改变数据的标签，所以可以用 Xf 与其自带的label，训练一个discriminator用来判别 Xt 。

# **Non-generative models**

Deep DA的关键是从source和target样本中学习领域不变的表示。有了这些表示,两个域的分布可以足够相似，这样即使在source样本上训练，classifier也会被欺骗，可以直接在target中使用。因此，表征是否为领域混淆对知识转移至关重要。受GAN的启发，引入discriminator产生的域混淆损失来提高无generator deep DA的性能。

这篇文章提出ADDA方法，提出一个同样的框架，认为目前基于对抗的域自适应方法都是该通用框架的一个实例。作者首先与用源域的数据预训练一个分离器。然后再利用GAN的结构将目标域的数据投影到源域。最后将源域的分类器用于目标域的分类。其实和上一篇文章的思路差不多，只不过就是将不同的步骤分开完成，没有耦合在一起。

# **Reconstruction-based**

大名鼎鼎的CycleGAN，其实也是用了类似于自编码器的结构，实现了风格迁移，做出了很多有趣的应用。

要将图片 X 风格转换到 Y 风格，比如现实风格变成卡通风格，那么可以用一个生成器 G 生成 Y^ ，然后用一个判别器 Dy 判断真假。其实这边并不要求数据是一一对应的，也就是一个图片 X 训练的时候，没有与其对应的 Y 。那么怎么保证 X 映射过去后内容不变呢？想法是我再让它映射回来呗，是不是很像个自编码器！而且保持原有结构映射回来，肯定比丢掉结构后变成完全不相关的图片再映射回来要容易很多，显然网络会选择前者。有点奥朗姆剃刀的意思，选简单的那个嘛。所以再设计一个生成器 F ，将 Y 映射回X，用另一个判别器 Dx 判别真假。对 Y 的数据，用同样的 、F、G 映射回 Y 。所以整个网络一共有两个生成器 G、F ，两个判别器 、Dx、Dy 。

与CycleGAN想法类似的DualGAN，唯一有点差别的是损失用了WGAN的损失。该生成器在镜像下采样和上采样层之间配置了跳跃连接，使其成为一个U型网络来共享底层信息(例如,物体形状、纹理、杂乱等)。对于判别器，采用Markovian patch-GAN架构捕获局部高频信息。

DiscoGAN，核心思想也是和CycleGAN和dualGAN一样的。在DiscoGAN中，可以使用多种形式的距离函数，如均方误差( MSE )、余弦距离和铰链损失作为重建损失，并将网络应用于翻译图像，在保持所有其他组件的同时，改变包括头发颜色、性别和方向在内的指定属性。

# Heterogeneous

StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks

之前提到的都是处理的图片到图片到自适应，这篇文章处理由文本生成图片。其实大家看图就能知道怎么做了。生成器先将文本通过某种方式编码到特征空间，比如词向量。然后和GAN的输入噪声合并，一起生成对应的图片。先生成64x64的图片，再从64x64生成256x256的。

High-quality facial photo-sketch synthesis using multi-adversarial networks

基于重构的方法，类似于CycleGAN，处理的是真实图片与素描的转换。创新之处在于用了多个判别器对抗，在图片的不同尺寸上进行生成对抗的过程，这样做的好处是能够生成高清的图像。

# Thinking & Plan

文章大部分篇幅在介绍one-step DA，multi-step DA着墨不多，是否multi-step DA问题研究较少。

文章大部分介绍homogeneous DA，是否heterogeneous DA更值得关注。

文章总结的工作大部分以分类为主，谈到分割的内容不多，而在医学影像领域分割是很重要的一个人物，是否应该去关注一些DA中分割的内容。

文章是18年发表的，后续至今Deep DA领域的发展需要继续去关注。